
> phantomjs@1.9.20 install /root/Targets/poncho/node_modules/phantomjs
> node install.js

PhantomJS not found on PATH
Downloading https://github.com/Medium/phantomjs/releases/download/v1.9.19/phantomjs-1.9.8-linux-x86_64.tar.bz2
Saving to /root/Targets/poncho/node_modules/phantomjs/phantomjs/phantomjs-1.9.8-linux-x86_64.tar.bz2
Receiving...

Received 12854K total.
Extracting tar contents (via spawned process)
Removing /root/Targets/poncho/node_modules/phantomjs/lib/phantom
Copying extracted folder /root/Targets/poncho/node_modules/phantomjs/phantomjs/phantomjs-1.9.8-linux-x86_64.tar.bz2-extract-1506915745959/phantomjs-1.9.8-linux-x86_64 -> /root/Targets/poncho/node_modules/phantomjs/lib/phantom
Writing location.js file
Done. Phantomjs binary available at /root/Targets/poncho/node_modules/phantomjs/lib/phantom/bin/phantomjs
/root/Targets/poncho
└─┬ poncho@0.1.1 
  ├─┬ blanket@1.1.10 
  │ ├── acorn@1.2.2 
  │ ├── falafel@1.2.0 
  │ ├── foreach@2.0.5 
  │ ├── isarray@0.0.1 
  │ ├── object-keys@1.0.11 
  │ └── xtend@4.0.1 
  ├── commander@2.1.0 
  ├─┬ node-static@0.7.10 
  │ ├── colors@1.1.2 
  │ ├── mime@1.4.1 
  │ └─┬ optimist@0.6.1 
  │   ├── minimist@0.0.10 
  │   └── wordwrap@0.0.3 
  └─┬ phantomjs@1.9.20 
    ├─┬ extract-zip@1.5.0 
    │ ├─┬ concat-stream@1.5.0 
    │ │ ├── inherits@2.0.3 
    │ │ ├─┬ readable-stream@2.0.6 
    │ │ │ ├── core-util-is@1.0.2 
    │ │ │ ├── isarray@1.0.0 
    │ │ │ ├── process-nextick-args@1.0.7 
    │ │ │ ├── string_decoder@0.10.31 
    │ │ │ └── util-deprecate@1.0.2 
    │ │ └── typedarray@0.0.6 
    │ ├── debug@0.7.4 
    │ ├─┬ mkdirp@0.5.0 
    │ │ └── minimist@0.0.8 
    │ └─┬ yauzl@2.4.1 
    │   └─┬ fd-slicer@1.0.1 
    │     └── pend@1.2.0 
    ├─┬ fs-extra@0.26.7 
    │ ├── graceful-fs@4.1.11 
    │ ├── jsonfile@2.4.0 
    │ ├── klaw@1.3.1 
    │ ├── path-is-absolute@1.0.1 
    │ └─┬ rimraf@2.6.2 
    │   └─┬ glob@7.1.2 
    │     ├── fs.realpath@1.0.0 
    │     ├─┬ inflight@1.0.6 
    │     │ └── wrappy@1.0.2 
    │     ├─┬ minimatch@3.0.4 
    │     │ └─┬ brace-expansion@1.1.8 
    │     │   ├── balanced-match@1.0.0 
    │     │   └── concat-map@0.0.1 
    │     └── once@1.4.0 
    ├─┬ hasha@2.2.0 
    │ ├── is-stream@1.1.0 
    │ └─┬ pinkie-promise@2.0.1 
    │   └── pinkie@2.0.4 
    ├── kew@0.7.0 
    ├── progress@1.1.8 
    ├─┬ request@2.67.0 
    │ ├── aws-sign2@0.6.0 
    │ ├── bl@1.0.3 
    │ ├── caseless@0.11.0 
    │ ├─┬ combined-stream@1.0.5 
    │ │ └── delayed-stream@1.0.0 
    │ ├── extend@3.0.1 
    │ ├── forever-agent@0.6.1 
    │ ├─┬ form-data@1.0.1 
    │ │ └─┬ async@2.5.0 
    │ │   └── lodash@4.17.4 
    │ ├─┬ har-validator@2.0.6 
    │ │ ├─┬ chalk@1.1.3 
    │ │ │ ├── ansi-styles@2.2.1 
    │ │ │ ├── escape-string-regexp@1.0.5 
    │ │ │ ├─┬ has-ansi@2.0.0 
    │ │ │ │ └── ansi-regex@2.1.1 
    │ │ │ ├── strip-ansi@3.0.1 
    │ │ │ └── supports-color@2.0.0 
    │ │ ├── commander@2.11.0 
    │ │ └─┬ is-my-json-valid@2.16.1 
    │ │   ├── generate-function@2.0.0 
    │ │   ├─┬ generate-object-property@1.2.0 
    │ │   │ └── is-property@1.0.2 
    │ │   └── jsonpointer@4.0.1 
    │ ├─┬ hawk@3.1.3 
    │ │ ├── boom@2.10.1 
    │ │ ├── cryptiles@2.0.5 
    │ │ ├── hoek@2.16.3 
    │ │ └── sntp@1.0.9 
    │ ├─┬ http-signature@1.1.1 
    │ │ ├── assert-plus@0.2.0 
    │ │ ├─┬ jsprim@1.4.1 
    │ │ │ ├── assert-plus@1.0.0 
    │ │ │ ├── extsprintf@1.3.0 
    │ │ │ ├── json-schema@0.2.3 
    │ │ │ └─┬ verror@1.10.0 
    │ │ │   └── assert-plus@1.0.0 
    │ │ └─┬ sshpk@1.13.1 
    │ │   ├── asn1@0.2.3 
    │ │   ├── assert-plus@1.0.0 
    │ │   ├── bcrypt-pbkdf@1.0.1 
    │ │   ├─┬ dashdash@1.14.1 
    │ │   │ └── assert-plus@1.0.0 
    │ │   ├── ecc-jsbn@0.1.1 
    │ │   ├─┬ getpass@0.1.7 
    │ │   │ └── assert-plus@1.0.0 
    │ │   ├── jsbn@0.1.1 
    │ │   └── tweetnacl@0.14.5 
    │ ├── is-typedarray@1.0.0 
    │ ├── isstream@0.1.2 
    │ ├── json-stringify-safe@5.0.1 
    │ ├─┬ mime-types@2.1.17 
    │ │ └── mime-db@1.30.0 
    │ ├── node-uuid@1.4.8 
    │ ├── oauth-sign@0.8.2 
    │ ├── qs@5.2.1 
    │ ├── stringstream@0.0.5 
    │ ├── tough-cookie@2.2.2 
    │ └── tunnel-agent@0.4.3 
    ├─┬ request-progress@2.0.1 
    │ └── throttleit@1.0.0 
    └─┬ which@1.2.14 
      └── isexe@2.0.0 

Setup Done exists, not setting up
:../FeatureTester/libs/:/root/Targets/poncho/node_modules
Set Default Z3_PATH to ./node_modules/z3javascript/bin/libz3.so
ExpoSE Master: /root/ExpoSE/lib/Harness/src/harness.js max concurrent: 16 max paths: 1000000
Setting timeout to 900000
*** [0 done /0 queued / 1 running / 0 errors / 0% coverage ] ****** [0 done /0 queued / 1 running / 0 errors / 0% coverage ] ****** [1 done /0 queued / 0 running / 1 errors / 32% coverage ] ***
*-- Stat Module Output --*
*-- concretizations: ["defineProperty","bound log"]
*-- Stat Module Done --*
*-- Test Case {"_bound":0} start 0.0378 took 3.6257s
*-- Errors occured in test {"_bound":0}
* Error: Tropigate failed because SyntaxError: Invalid number (365:22) on program var fs     = require('fs')
  , events = require('events')
  , buffer = require('buffer')
  , http   = require('http')
  , url    = require('url')
  , path   = require('path')
  , mime   = require('mime')
  , util   = require('./node-static/util');

// Current version
var version = [0, 7, 9];

var Server = function (root, options) {
    if (root && (typeof(root) === 'object')) { options = root; root = null }

    // resolve() doesn't normalize (to lowercase) drive letters on Windows
    this.root    = path.normalize(path.resolve(root || '.'));
    this.options = options || {};
    this.cache   = 3600;

    this.defaultHeaders  = {};
    this.options.headers = this.options.headers || {};

    this.options.indexFile = this.options.indexFile || "index.html";

    if ('cache' in this.options) {
        if (typeof(this.options.cache) === 'number') {
            this.cache = this.options.cache;
        } else if (! this.options.cache) {
            this.cache = false;
        }
    }

    if ('serverInfo' in this.options) {
        this.serverInfo = this.options.serverInfo.toString();
    } else {
        this.serverInfo = 'node-static/' + version.join('.');
    }

    this.defaultHeaders['server'] = this.serverInfo;

    if (this.cache !== false) {
        this.defaultHeaders['cache-control'] = 'max-age=' + this.cache;
    }

    for (var k in this.defaultHeaders) {
        this.options.headers[k] = this.options.headers[k] ||
                                  this.defaultHeaders[k];
    }
};

Server.prototype.serveDir = function (pathname, req, res, finish) {
    var htmlIndex = path.join(pathname, this.options.indexFile),
        that = this;

    fs.stat(htmlIndex, function (e, stat) {
        if (!e) {
            var status = 200;
            var headers = {};
            var originalPathname = decodeURI(url.parse(req.url).pathname);
            if (originalPathname.length && originalPathname.charAt(originalPathname.length - 1) !== '/') {
                return finish(301, { 'Location': originalPathname + '/' });
            } else {
                that.respond(null, status, headers, [htmlIndex], stat, req, res, finish);
            }
        } else {
            // Stream a directory of files as a single file.
            fs.readFile(path.join(pathname, 'index.json'), function (e, contents) {
                if (e) { return finish(404, {}) }
                var index = JSON.parse(contents);
                streamFiles(index.files);
            });
        }
    });
    function streamFiles(files) {
        util.mstat(pathname, files, function (e, stat) {
            if (e) { return finish(404, {}) }
            that.respond(pathname, 200, {}, files, stat, req, res, finish);
        });
    }
};

Server.prototype.serveFile = function (pathname, status, headers, req, res) {
    var that = this;
    var promise = new(events.EventEmitter);

    pathname = this.resolve(pathname);

    fs.stat(pathname, function (e, stat) {
        if (e) {
            return promise.emit('error', e);
        }
        that.respond(null, status, headers, [pathname], stat, req, res, function (status, headers) {
            that.finish(status, headers, req, res, promise);
        });
    });
    return promise;
};

Server.prototype.finish = function (status, headers, req, res, promise, callback) {
    var result = {
        status:  status,
        headers: headers,
        message: http.STATUS_CODES[status]
    };

    headers['server'] = this.serverInfo;

    if (!status || status >= 400) {
        if (callback) {
            callback(result);
        } else {
            if (promise.listeners('error').length > 0) {
                promise.emit('error', result);
            }
            else {
              res.writeHead(status, headers);
              res.end();
            }
        }
    } else {
        // Don't end the request here, if we're streaming;
        // it's taken care of in `prototype.stream`.
        if (status !== 200 || req.method !== 'GET') {
            res.writeHead(status, headers);
            res.end();
        }
        callback && callback(null, result);
        promise.emit('success', result);
    }
};

Server.prototype.servePath = function (pathname, status, headers, req, res, finish) {
    var that = this,
        promise = new(events.EventEmitter);

    pathname = this.resolve(pathname);

    // Make sure we're not trying to access a
    // file outside of the root.
    if (pathname.indexOf(that.root) === 0) {
        fs.stat(pathname, function (e, stat) {
            if (e) {
                finish(404, {});
            } else if (stat.isFile()) {      // Stream a single file.
                that.respond(null, status, headers, [pathname], stat, req, res, finish);
            } else if (stat.isDirectory()) { // Stream a directory of files.
                that.serveDir(pathname, req, res, finish);
            } else {
                finish(400, {});
            }
        });
    } else {
        // Forbidden
        finish(403, {});
    }
    return promise;
};

Server.prototype.resolve = function (pathname) {
    return path.resolve(path.join(this.root, pathname));
};

Server.prototype.serve = function (req, res, callback) {
    var that    = this,
        promise = new(events.EventEmitter),
        pathname;

    var finish = function (status, headers) {
        that.finish(status, headers, req, res, promise, callback);
    };

    try {
        pathname = decodeURI(url.parse(req.url).pathname);
    }
    catch(e) {
        return process.nextTick(function() {
            return finish(400, {});
        });
    }

    process.nextTick(function () {
        that.servePath(pathname, 200, {}, req, res, finish).on('success', function (result) {
            promise.emit('success', result);
        }).on('error', function (err) {
            promise.emit('error');
        });
    });
    if (! callback) { return promise }
};

/* Check if we should consider sending a gzip version of the file based on the
 * file content type and client's Accept-Encoding header value.
 */
Server.prototype.gzipOk = function (req, contentType) {
    var enable = this.options.gzip;
    if(enable &&
        (typeof enable === 'boolean' ||
            (contentType && (enable instanceof RegExp) && enable.test(contentType)))) {
        var acceptEncoding = req.headers['accept-encoding'];
        return acceptEncoding && acceptEncoding.indexOf("gzip") >= 0;
    }
    return false;
}

/* Send a gzipped version of the file if the options and the client indicate gzip is enabled and
 * we find a .gz file mathing the static resource requested.
 */
Server.prototype.respondGzip = function (pathname, status, contentType, _headers, files, stat, req, res, finish) {
    var that = this;
    if (files.length == 1 && this.gzipOk(req, contentType)) {
        var gzFile = files[0] + ".gz";
        fs.stat(gzFile, function (e, gzStat) {
            if (!e && gzStat.isFile()) {
                var vary = _headers['Vary'];
                _headers['Vary'] = (vary && vary != 'Accept-Encoding' ? vary + ', ' : '') + 'Accept-Encoding';
                _headers['Content-Encoding'] = 'gzip';
                stat.size = gzStat.size;
                files = [gzFile];
            }
            that.respondNoGzip(pathname, status, contentType, _headers, files, stat, req, res, finish);
        });
    } else {
        // Client doesn't want gzip or we're sending multiple files
        that.respondNoGzip(pathname, status, contentType, _headers, files, stat, req, res, finish);
    }
}

Server.prototype.parseByteRange = function (req, stat) {
    var byteRange = {
      from: 0,
      to: 0,
      valid: false
    }

    var rangeHeader = req.headers['range'];
    var flavor = 'bytes=';

    if (rangeHeader) {
        if (rangeHeader.indexOf(flavor) == 0 && rangeHeader.indexOf(',') == -1) {
            /* Parse */
            rangeHeader = rangeHeader.substr(flavor.length).split('-');
            byteRange.from = parseInt(rangeHeader[0]);
            byteRange.to = parseInt(rangeHeader[1]);

            /* Replace empty fields of differential requests by absolute values */
            if (isNaN(byteRange.from) && !isNaN(byteRange.to)) {
                byteRange.from = stat.size - byteRange.to;
                byteRange.to = stat.size ? stat.size - 1 : 0;
            } else if (!isNaN(byteRange.from) && isNaN(byteRange.to)) {
                byteRange.to = stat.size ? stat.size - 1 : 0;
            }

            /* General byte range validation */
            if (!isNaN(byteRange.from) && !!byteRange.to && 0 <= byteRange.from && byteRange.from < byteRange.to) {
                byteRange.valid = true;
            } else {
                console.warn("Request contains invalid range header: ", rangeHeader);
            }
        } else {
            console.warn("Request contains unsupported range header: ", rangeHeader);
        }
    }
    return byteRange;
}

Server.prototype.respondNoGzip = function (pathname, status, contentType, _headers, files, stat, req, res, finish) {
    var mtime           = Date.parse(stat.mtime),
        key             = pathname || files[0],
        headers         = {},
        clientETag      = req.headers['if-none-match'],
        clientMTime     = Date.parse(req.headers['if-modified-since']),
        startByte       = 0,
        length          = stat.size,
        byteRange       = this.parseByteRange(req, stat);

    /* Handle byte ranges */
    if (files.length == 1 && byteRange.valid) {
        if (byteRange.to < length) {

            // Note: HTTP Range param is inclusive
            startByte = byteRange.from;
            length = byteRange.to - byteRange.from + 1;
            status = 206;

            // Set Content-Range response header (we advertise initial resource size on server here (stat.size))
            headers['Content-Range'] = 'bytes ' + byteRange.from + '-' + byteRange.to + '/' + stat.size;

        } else {
            byteRange.valid = false;
            console.warn("Range request exceeds file boundaries, goes until byte no", byteRange.to, "against file size of", length, "bytes");
        }
    }

    /* In any case, check for unhandled byte range headers */
    if (!byteRange.valid && req.headers['range']) {
        console.error(new Error("Range request present but invalid, might serve whole file instead"));
    }

    // Copy default headers
    for (var k in this.options.headers) {  headers[k] = this.options.headers[k] }
    // Copy custom headers
    for (var k in _headers) { headers[k] = _headers[k] }

    headers['Etag']          = JSON.stringify([stat.ino, stat.size, mtime].join('-'));
    headers['Date']          = new(Date)().toUTCString();
    headers['Last-Modified'] = new(Date)(stat.mtime).toUTCString();
    headers['Content-Type']   = contentType;
    headers['Content-Length'] = length;

    for (var k in _headers) { headers[k] = _headers[k] }

    // Conditional GET
    // If the "If-Modified-Since" or "If-None-Match" headers
    // match the conditions, send a 304 Not Modified.
    if ((clientMTime  || clientETag) &&
        (!clientETag  || clientETag === headers['Etag']) &&
        (!clientMTime || clientMTime >= mtime)) {
        // 304 response should not contain entity headers
        ['Content-Encoding',
         'Content-Language',
         'Content-Length',
         'Content-Location',
         'Content-MD5',
         'Content-Range',
         'Content-Type',
         'Expires',
         'Last-Modified'].forEach(function (entityHeader) {
            delete headers[entityHeader];
        });
        finish(304, headers);
    } else {
        res.writeHead(status, headers);

        this.stream(key, files, length, startByte, res, function (e) {
            if (e) { return finish(500, {}) }
            finish(status, headers);
        });
    }
};

Server.prototype.respond = function (pathname, status, _headers, files, stat, req, res, finish) {
    var contentType = _headers['Content-Type'] ||
                      mime.lookup(files[0]) ||
                      'application/octet-stream';

    if(this.options.gzip) {
        this.respondGzip(pathname, status, contentType, _headers, files, stat, req, res, finish);
    } else {
        this.respondNoGzip(pathname, status, contentType, _headers, files, stat, req, res, finish);
    }
}

Server.prototype.stream = function (pathname, files, length, startByte, res, callback) {

    (function streamFile(files, offset) {
        var file = files.shift();

        if (file) {
            file = path.resolve(file) === path.normalize(file)  ? file : path.join(pathname || '.', file);

            // Stream the file to the client
            fs.createReadStream(file, {
                flags: 'r',
                mode: 0666,
                start: startByte,
                end: startByte + (length ? length - 1 : 0)
            }).on('data', function (chunk) {
                // Bounds check the incoming chunk and offset, as copying
                // a buffer from an invalid offset will throw an error and crash
                if (chunk.length && offset < length && offset >= 0) {
                    offset += chunk.length;
                }
            }).on('close', function () {
                streamFile(files, offset);
            }).on('error', function (err) {
                callback(err);
                console.error(err);
            }).pipe(res, { end: false });
        } else {
            res.end();
            callback(null, offset);
        }
    })(files.slice(0), 0);
};

// Exports
exports.Server       = Server;
exports.version      = version;
exports.mime         = mime;



 at SyntaxError: Invalid number (365:22)
    at Parser.pp$4.raise (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2221:15)
    at Parser.pp$7.readNumber (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2896:52)
    at Parser.pp$7.getTokenFromCode (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2720:19)
    at Parser.pp$7.readToken (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2477:17)
    at Parser.readToken (/root/ExpoSE/lib/Tropigate/bin/Tokens.js:124:26)
    at Parser.pp$7.nextToken (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2468:15)
    at Parser.pp$7.next (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2413:10)
    at Parser.pp.eat (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:536:12)
    at Parser.pp$3.parsePropertyValue (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1997:14)
    at Parser.pp$3.parseObj (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1989:14)
*-- Replay with NO_COMPILE=1 expoSE replay '/root/ExpoSE/lib/Harness/src/harness.js' '{"_bound":0}'
*-- Coverage Data
*- File /root/ExpoSE/lib/Harness/src/harness.js. Coverage (Term): 18% Coverage (LOC): 24%
*- File /root/ExpoSE/lib/S$/bin/symbols.js. Coverage (Term): 16% Coverage (LOC): 34%
*- File /root/Targets/poncho/node_modules/poncho/index.js. Coverage (Term): 33% Coverage (LOC): 56%
*- File /root/Targets/poncho/node_modules/poncho/lib/server.js. Coverage (Term): 18% Coverage (LOC): 19%
*- Re-run with EXPOSE_PRINT_COVERAGE=1 to print line by line coverage information
** ExpoSE Finished. 1 paths with 1 errors **
