/root/Targets/sfr-server
└─┬ sfr-server@1.0.2 
  ├─┬ babel-core@5.8.38 
  │ ├── babel-plugin-constant-folding@1.0.1 
  │ ├── babel-plugin-dead-code-elimination@1.0.2 
  │ ├── babel-plugin-eval@1.0.1 
  │ ├── babel-plugin-inline-environment-variables@1.0.1 
  │ ├── babel-plugin-jscript@1.0.4 
  │ ├── babel-plugin-member-expression-literals@1.0.1 
  │ ├── babel-plugin-property-literals@1.0.1 
  │ ├── babel-plugin-proto-to-assign@1.0.4 
  │ ├── babel-plugin-react-constant-elements@1.0.3 
  │ ├── babel-plugin-react-display-name@1.0.3 
  │ ├── babel-plugin-remove-console@1.0.1 
  │ ├── babel-plugin-remove-debugger@1.0.1 
  │ ├── babel-plugin-runtime@1.0.7 
  │ ├─┬ babel-plugin-undeclared-variables-check@1.0.2 
  │ │ └── leven@1.0.2 
  │ ├── babel-plugin-undefined-to-void@1.1.6 
  │ ├── babylon@5.8.38 
  │ ├── bluebird@2.11.0 
  │ ├─┬ chalk@1.1.3 
  │ │ ├── ansi-styles@2.2.1 
  │ │ ├── escape-string-regexp@1.0.5 
  │ │ ├─┬ has-ansi@2.0.0 
  │ │ │ └── ansi-regex@2.1.1 
  │ │ ├── strip-ansi@3.0.1 
  │ │ └── supports-color@2.0.0 
  │ ├── convert-source-map@1.5.0 
  │ ├── core-js@1.2.7 
  │ ├─┬ debug@2.6.9 
  │ │ └── ms@2.0.0 
  │ ├─┬ detect-indent@3.0.1 
  │ │ ├── get-stdin@4.0.1 
  │ │ └── minimist@1.2.0 
  │ ├── esutils@2.0.2 
  │ ├── fs-readdir-recursive@0.1.2 
  │ ├── globals@6.4.1 
  │ ├─┬ home-or-tmp@1.0.0 
  │ │ ├── os-tmpdir@1.0.2 
  │ │ └── user-home@1.1.1 
  │ ├─┬ is-integer@1.0.7 
  │ │ └─┬ is-finite@1.0.2 
  │ │   └── number-is-nan@1.0.1 
  │ ├── js-tokens@1.0.1 
  │ ├── json5@0.4.0 
  │ ├── lodash@3.10.1 
  │ ├─┬ minimatch@2.0.10 
  │ │ └─┬ brace-expansion@1.1.8 
  │ │   ├── balanced-match@1.0.0 
  │ │   └── concat-map@0.0.1 
  │ ├─┬ output-file-sync@1.1.2 
  │ │ ├── graceful-fs@4.1.11 
  │ │ └── object-assign@4.1.1 
  │ ├── path-exists@1.0.0 
  │ ├── path-is-absolute@1.0.1 
  │ ├── private@0.1.7 
  │ ├─┬ regenerator@0.8.40 
  │ │ ├─┬ commoner@0.10.8 
  │ │ │ ├── commander@2.11.0 
  │ │ │ ├─┬ detective@4.5.0 
  │ │ │ │ ├── acorn@4.0.13 
  │ │ │ │ └── defined@1.0.0 
  │ │ │ ├── q@1.5.0 
  │ │ │ └─┬ recast@0.11.23 
  │ │ │   ├── ast-types@0.9.6 
  │ │ │   └── esprima@3.1.3 
  │ │ ├─┬ defs@1.1.1 
  │ │ │ ├─┬ alter@0.2.0 
  │ │ │ │ └── stable@0.1.6 
  │ │ │ ├── ast-traverse@0.1.1 
  │ │ │ ├── breakable@1.0.0 
  │ │ │ ├── simple-fmt@0.1.0 
  │ │ │ ├── simple-is@0.2.0 
  │ │ │ ├── stringmap@0.2.2 
  │ │ │ ├── stringset@0.2.1 
  │ │ │ ├── tryor@0.1.2 
  │ │ │ └─┬ yargs@3.27.0 
  │ │ │   ├── camelcase@1.2.1 
  │ │ │   ├─┬ cliui@2.1.0 
  │ │ │   │ ├─┬ center-align@0.1.3 
  │ │ │   │ │ ├─┬ align-text@0.1.4 
  │ │ │   │ │ │ ├─┬ kind-of@3.2.2 
  │ │ │   │ │ │ │ └── is-buffer@1.1.5 
  │ │ │   │ │ │ ├── longest@1.0.1 
  │ │ │   │ │ │ └── repeat-string@1.6.1 
  │ │ │   │ │ └── lazy-cache@1.0.4 
  │ │ │   │ └── right-align@0.1.3 
  │ │ │   ├── decamelize@1.2.0 
  │ │ │   ├─┬ os-locale@1.4.0 
  │ │ │   │ └─┬ lcid@1.0.0 
  │ │ │   │   └── invert-kv@1.0.0 
  │ │ │   ├── window-size@0.1.4 
  │ │ │   └── y18n@3.2.1 
  │ │ ├── esprima-fb@15001.1001.0-dev-harmony-fb 
  │ │ ├─┬ recast@0.10.33 
  │ │ │ └── ast-types@0.8.12 
  │ │ └── through@2.3.8 
  │ ├─┬ regexpu@1.3.0 
  │ │ ├── esprima@2.7.3 
  │ │ ├── regenerate@1.3.3 
  │ │ ├── regjsgen@0.2.0 
  │ │ └─┬ regjsparser@0.1.5 
  │ │   └── jsesc@0.5.0 
  │ ├── repeating@1.1.3 
  │ ├─┬ resolve@1.4.0 
  │ │ └── path-parse@1.0.5 
  │ ├── shebang-regex@1.0.0 
  │ ├── slash@1.0.0 
  │ ├── source-map@0.5.7 
  │ ├─┬ source-map-support@0.2.10 
  │ │ └── source-map@0.1.32 
  │ ├── to-fast-properties@1.0.3 
  │ ├── trim-right@1.0.1 
  │ └── try-resolve@1.0.1 
  ├── coffee-script@1.9.3 
  ├─┬ connect@3.3.5 
  │ ├─┬ debug@2.1.3 
  │ │ └── ms@0.7.0 
  │ ├─┬ finalhandler@0.3.4 
  │ │ ├─┬ debug@2.1.3 
  │ │ │ └── ms@0.7.0 
  │ │ ├── escape-html@1.0.1 
  │ │ └─┬ on-finished@2.2.1 
  │ │   └── ee-first@1.1.0 
  │ ├── parseurl@1.3.2 
  │ └── utils-merge@1.0.0 
  ├─┬ connect-logger@0.0.1 
  │ └── moment@2.18.1 
  ├─┬ edp-core@1.0.32 
  │ ├─┬ chalk@1.0.0 
  │ │ ├─┬ has-ansi@1.0.3 
  │ │ │ └── ansi-regex@1.1.1 
  │ │ ├── strip-ansi@2.0.1 
  │ │ └── supports-color@1.3.1 
  │ ├── edp-config@1.0.2 
  │ ├── esprima@2.2.0 
  │ ├── estraverse@4.1.1 
  │ ├─┬ glob@5.0.15 
  │ │ ├─┬ inflight@1.0.6 
  │ │ │ └── wrappy@1.0.2 
  │ │ ├── inherits@2.0.3 
  │ │ └── once@1.4.0 
  │ ├── iconv-lite@0.4.19 
  │ └── semver@4.3.6 
  ├─┬ handlebars@3.0.3 
  │ ├─┬ optimist@0.6.1 
  │ │ ├── minimist@0.0.10 
  │ │ └── wordwrap@0.0.2 
  │ ├─┬ source-map@0.1.43 
  │ │ └── amdefine@1.0.1 
  │ └─┬ uglify-js@2.3.6 
  │   ├── async@0.2.10 
  │   ├── optimist@0.3.7 
  │   └── source-map@0.1.43 
  ├── html2js@0.2.0 
  ├── http2@3.3.7 
  ├─┬ less@1.7.5 
  │ ├─┬ clean-css@2.2.23 
  │ │ └── commander@2.2.0 
  │ ├─┬ graceful-fs@3.0.11 
  │ │ └── natives@1.1.0 
  │ ├── mime@1.2.11 
  │ ├─┬ mkdirp@0.5.1 
  │ │ └── minimist@0.0.8 
  │ ├─┬ request@2.40.0 
  │ │ ├── aws-sign2@0.5.0 
  │ │ ├── forever-agent@0.5.2 
  │ │ ├─┬ form-data@0.1.4 
  │ │ │ ├── async@0.9.2 
  │ │ │ └─┬ combined-stream@0.0.7 
  │ │ │   └── delayed-stream@0.0.5 
  │ │ ├─┬ hawk@1.1.1 
  │ │ │ ├── boom@0.4.2 
  │ │ │ ├── cryptiles@0.2.2 
  │ │ │ ├── hoek@0.9.1 
  │ │ │ └── sntp@0.2.4 
  │ │ ├─┬ http-signature@0.10.1 
  │ │ │ ├── asn1@0.1.11 
  │ │ │ ├── assert-plus@0.1.5 
  │ │ │ └── ctype@0.5.3 
  │ │ ├── json-stringify-safe@5.0.1 
  │ │ ├── mime-types@1.0.2 
  │ │ ├── node-uuid@1.4.8 
  │ │ ├── oauth-sign@0.3.0 
  │ │ ├── qs@1.0.2 
  │ │ ├── stringstream@0.0.5 
  │ │ ├─┬ tough-cookie@2.3.3 
  │ │ │ └── punycode@1.4.1 
  │ │ └── tunnel-agent@0.4.3 
  │ └── source-map@0.1.43 
  ├─┬ markdown@0.5.0 
  │ └─┬ nopt@2.1.2 
  │   └── abbrev@1.1.1 
  ├─┬ path-to-regexp@1.1.1 
  │ └── isarray@0.0.1 
  ├─┬ postcss@5.2.17 
  │ ├── js-base64@2.3.2 
  │ └─┬ supports-color@3.2.3 
  │   └── has-flag@1.0.0 
  ├── sfr-log@1.0.1 
  ├─┬ stylus@0.51.1 
  │ ├── css-parse@1.7.0 
  │ ├─┬ glob@3.2.11 
  │ │ └─┬ minimatch@0.3.0 
  │ │   ├── lru-cache@2.7.3 
  │ │   └── sigmund@1.0.1 
  │ ├── mkdirp@0.3.5 
  │ ├── sax@0.5.8 
  │ └── source-map@0.1.43 
  └── underscore@1.8.3 

Setup Done exists, not setting up
:../FeatureTester/libs/:/root/Targets/sfr-server/node_modules
Set Default Z3_PATH to ./node_modules/z3javascript/bin/libz3.so
ExpoSE Master: /root/ExpoSE/lib/Harness/src/harness.js max concurrent: 16 max paths: 1000000
Setting timeout to 900000
*** [0 done /0 queued / 1 running / 0 errors / 0% coverage ] ****** [0 done /0 queued / 1 running / 0 errors / 0% coverage ] ****** [1 done /0 queued / 0 running / 1 errors / 12% coverage ] ***
*-- Stat Module Output --*
*-- concretizations: ["defineProperty","bound log"]
*-- Stat Module Done --*
*-- Test Case {"_bound":0} start 0.0588 took 6.782s
*-- Errors occured in test {"_bound":0}
* Error: Tropigate failed because SyntaxError: Unexpected token (1:82) on program var assert = require('assert');

var Serializer   = require('./framer').Serializer;
var Deserializer = require('./framer').Deserializer;
var Compressor   = require('./compressor').Compressor;
var Decompressor = require('./compressor').Decompressor;
var Connection   = require('./connection').Connection;
var Duplex       = require('stream').Duplex;
var Transform    = require('stream').Transform;

exports.Endpoint = Endpoint;

// The Endpoint class
// ==================

// Public API
// ----------

// - **new Endpoint(log, role, settings, filters)**: create a new Endpoint.
//
//   - `log`: bunyan logger of the parent
//   - `role`: 'CLIENT' or 'SERVER'
//   - `settings`: initial HTTP/2 settings
//   - `filters`: a map of functions that filter the traffic between components (for debugging or
//     intentional failure injection).
//
//     Filter functions get three arguments:
//     1. `frame`: the current frame
//     2. `forward(frame)`: function that can be used to forward a frame to the next component
//     3. `done()`: callback to signal the end of the filter process
//
//     Valid filter names and their position in the stack:
//     - `beforeSerialization`: after compression, before serialization
//     - `beforeCompression`: after multiplexing, before compression
//     - `afterDeserialization`: after deserialization, before decompression
//     - `afterDecompression`: after decompression, before multiplexing
//
// * **Event: 'stream' (Stream)**: 'stream' event forwarded from the underlying Connection
//
// * **Event: 'error' (type)**: signals an error
//
// * **createStream(): Stream**: initiate a new stream (forwarded to the underlying Connection)
//
// * **close([error])**: close the connection with an error code

// Constructor
// -----------

// The process of initialization:
function Endpoint(log, role, settings, filters) {
  Duplex.call(this);

  // * Initializing logging infrastructure
  this._log = log.child({ component: 'endpoint', e: this });

  // * First part of the handshake process: sending and receiving the client connection header
  //   prelude.
  assert((role === 'CLIENT') || role === 'SERVER');
  if (role === 'CLIENT') {
    this._writePrelude();
  } else {
    this._readPrelude();
  }

  // * Initialization of component. This includes the second part of the handshake process:
  //   sending the first SETTINGS frame. This is done by the connection class right after
  //   initialization.
  this._initializeDataFlow(role, settings, filters || {});

  // * Initialization of management code.
  this._initializeManagement();

  // * Initializing error handling.
  this._initializeErrorHandling();
}
Endpoint.prototype = Object.create(Duplex.prototype, { constructor: { value: Endpoint } });

// Handshake
// ---------

var CLIENT_PRELUDE = new Buffer('PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n');

// Writing the client header is simple and synchronous.
Endpoint.prototype._writePrelude = function _writePrelude() {
  this._log.debug('Sending the client connection header prelude.');
  this.push(CLIENT_PRELUDE);
};

// The asynchronous process of reading the client header:
Endpoint.prototype._readPrelude = function _readPrelude() {
  // * progress in the header is tracker using a `cursor`
  var cursor = 0;

  // * `_write` is temporarily replaced by the comparator function
  this._write = function _temporalWrite(chunk, encoding, done) {
    // * which compares the stored header with the current `chunk` byte by byte and emits the
    //   'error' event if there's a byte that doesn't match
    var offset = cursor;
    while(cursor < CLIENT_PRELUDE.length && (cursor - offset) < chunk.length) {
      if (CLIENT_PRELUDE[cursor] !== chunk[cursor - offset]) {
        this._log.fatal({ cursor: cursor, offset: offset, chunk: chunk },
                        'Client connection header prelude does not match.');
        this._error('handshake', 'PROTOCOL_ERROR');
        return;
      }
      cursor += 1;
    }

    // * if the whole header is over, and there were no error then restore the original `_write`
    //   and call it with the remaining part of the current chunk
    if (cursor === CLIENT_PRELUDE.length) {
      this._log.debug('Successfully received the client connection header prelude.');
      delete this._write;
      chunk = chunk.slice(cursor - offset);
      this._write(chunk, encoding, done);
    }
  };
};

// Data flow
// ---------

//     +---------------------------------------------+
//     |                                             |
//     |   +-------------------------------------+   |
//     |   | +---------+ +---------+ +---------+ |   |
//     |   | | stream1 | | stream2 | |   ...   | |   |
//     |   | +---------+ +---------+ +---------+ |   |
//     |   |             connection              |   |
//     |   +-------------------------------------+   |
//     |             |                 ^             |
//     |        pipe |                 | pipe        |
//     |             v                 |             |
//     |   +------------------+------------------+   |
//     |   |    compressor    |   decompressor   |   |
//     |   +------------------+------------------+   |
//     |             |                 ^             |
//     |        pipe |                 | pipe        |
//     |             v                 |             |
//     |   +------------------+------------------+   |
//     |   |    serializer    |   deserializer   |   |
//     |   +------------------+------------------+   |
//     |             |                 ^             |
//     |     _read() |                 | _write()    |
//     |             v                 |             |
//     |      +------------+     +-----------+       |
//     |      |output queue|     |input queue|       |
//     +------+------------+-----+-----------+-------+
//                   |                 ^
//            read() |                 | write()
//                   v                 |

function createTransformStream(filter) {
  var transform = new Transform({ objectMode: true });
  var push = transform.push.bind(transform);
  transform._transform = function(frame, encoding, done) {
    filter(frame, push, done);
  };
  return transform;
}

function pipeAndFilter(stream1, stream2, filter) {
  if (filter) {
    stream1.pipe(createTransformStream(filter)).pipe(stream2);
  } else {
    stream1.pipe(stream2);
  }
}

Endpoint.prototype._initializeDataFlow = function _initializeDataFlow(role, settings, filters) {
  var firstStreamId, compressorRole, decompressorRole;
  if (role === 'CLIENT') {
    firstStreamId = 1;
    compressorRole = 'REQUEST';
    decompressorRole = 'RESPONSE';
  } else {
    firstStreamId = 2;
    compressorRole = 'RESPONSE';
    decompressorRole = 'REQUEST';
  }

  this._serializer   = new Serializer(this._log);
  this._deserializer = new Deserializer(this._log);
  this._compressor   = new Compressor(this._log, compressorRole);
  this._decompressor = new Decompressor(this._log, decompressorRole);
  this._connection   = new Connection(this._log, firstStreamId, settings);

  pipeAndFilter(this._connection, this._compressor, filters.beforeCompression);
  pipeAndFilter(this._compressor, this._serializer, filters.beforeSerialization);
  pipeAndFilter(this._deserializer, this._decompressor, filters.afterDeserialization);
  pipeAndFilter(this._decompressor, this._connection, filters.afterDecompression);

  this._connection.on('ACKNOWLEDGED_SETTINGS_HEADER_TABLE_SIZE',
                      this._decompressor.setTableSizeLimit.bind(this._decompressor));
  this._connection.on('RECEIVING_SETTINGS_HEADER_TABLE_SIZE',
                      this._compressor.setTableSizeLimit.bind(this._compressor));
};

var noread = {};
Endpoint.prototype._read = function _read() {
  this._readableState.sync = true;
  var moreNeeded = noread, chunk;
  while (moreNeeded && (chunk = this._serializer.read())) {
    moreNeeded = this.push(chunk);
  }
  if (moreNeeded === noread) {
    this._serializer.once('readable', this._read.bind(this));
  }
  this._readableState.sync = false;
};

Endpoint.prototype._write = function _write(chunk, encoding, done) {
  this._deserializer.write(chunk, encoding, done);
};

// Management
// --------------

Endpoint.prototype._initializeManagement = function _initializeManagement() {
  this._connection.on('stream', this.emit.bind(this, 'stream'));
};

Endpoint.prototype.createStream = function createStream() {
  return this._connection.createStream();
};

// Error handling
// --------------

Endpoint.prototype._initializeErrorHandling = function _initializeErrorHandling() {
  this._serializer.on('error', this._error.bind(this, 'serializer'));
  this._deserializer.on('error', this._error.bind(this, 'deserializer'));
  this._compressor.on('error', this._error.bind(this, 'compressor'));
  this._decompressor.on('error', this._error.bind(this, 'decompressor'));
  this._connection.on('error', this._error.bind(this, 'connection'));

  this._connection.on('peerError', this.emit.bind(this, 'peerError'));
};

Endpoint.prototype._error = function _error(component, error) {
  this._log.fatal({ source: component, message: error }, 'Fatal error, closing connection');
  this.close(error);
  setImmediate(this.emit.bind(this, 'error', error));
};

Endpoint.prototype.close = function close(error) {
  this._connection.close(error);
};

// Bunyan serializers
// ------------------

exports.serializers = {};

var nextId = 0;
exports.serializers.e = function(endpoint) {
  if (!('id' in endpoint)) {
    endpoint.id = nextId;
    nextId += 1;
  }
  return endpoint.id;
};
 at SyntaxError: Unexpected token (1:82)
    at Parser.pp$4.raise (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2221:15)
    at Parser.pp.unexpected (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:603:10)
    at Parser.pp$2.parseBindingAtom (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1417:12)
    at Parser.parseBindingAtom (/root/ExpoSE/lib/Tropigate/bin/FunctionSignatures.js:49:30)
    at Parser.pp$1.parseVarId (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1049:20)
    at Parser.pp$1.parseVar (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1032:14)
    at Parser.pp$1.parseVarStatement (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:917:10)
    at Parser.pp$1.parseStatement (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:706:19)
    at Parser.parseStatement (/root/ExpoSE/lib/Tropigate/bin/Statements.js:104:30)
    at Parser.pp$1.parseTopLevel (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:638:25)
*-- Replay with NO_COMPILE=1 expoSE replay '/root/ExpoSE/lib/Harness/src/harness.js' '{"_bound":0}'
*-- Coverage Data
*- File /root/ExpoSE/lib/Harness/src/harness.js. Coverage (Term): 18% Coverage (LOC): 24%
*- File /root/ExpoSE/lib/S$/bin/symbols.js. Coverage (Term): 16% Coverage (LOC): 34%
*- File /root/Targets/sfr-server/node_modules/sfr-server/index.js. Coverage (Term): 48% Coverage (LOC): 67%
*- File /root/Targets/sfr-server/node_modules/sfr-server/lib/start.js. Coverage (Term): 19% Coverage (LOC): 24%
*- File /root/Targets/sfr-server/node_modules/http2/lib/index.js. Coverage (Term): 80% Coverage (LOC): 100%
*- File /root/Targets/sfr-server/node_modules/http2/lib/http.js. Coverage (Term): 3% Coverage (LOC): 4%
*- File /root/Targets/sfr-server/node_modules/http2/lib/protocol/index.js. Coverage (Term): 31% Coverage (LOC): 29%
*- Re-run with EXPOSE_PRINT_COVERAGE=1 to print line by line coverage information
** ExpoSE Finished. 1 paths with 1 errors **
