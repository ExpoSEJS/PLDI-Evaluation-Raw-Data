
> ws@0.4.31 install /root/Targets/breach_core/node_modules/ws
> (node-gyp rebuild 2> builderror.log) || (exit 0)

make: Entering directory '/root/Targets/breach_core/node_modules/ws/build'
  CXX(target) Release/obj.target/bufferutil/src/bufferutil.o
bufferutil.target.mk:96: recipe for target 'Release/obj.target/bufferutil/src/bufferutil.o' failed
make: Leaving directory '/root/Targets/breach_core/node_modules/ws/build'
/root/Targets/breach_core
└─┬ breach_core@0.3.18-alpha.4 
  ├── async@0.9.2 
  ├─┬ body-parser@1.0.2 
  │ ├── qs@0.6.6 
  │ ├─┬ raw-body@1.1.7 
  │ │ ├── bytes@1.0.0 
  │ │ └── string_decoder@0.10.31 
  │ └── type-is@1.1.0 
  ├─┬ exo_browser@0.6.9 
  │ └── async@0.7.0 
  ├─┬ express@4.0.0 
  │ ├─┬ accepts@1.0.0 
  │ │ └── negotiator@0.3.0 
  │ ├── buffer-crc32@0.2.1 
  │ ├── cookie@0.1.0 
  │ ├── cookie-signature@1.0.3 
  │ ├── debug@0.8.1 
  │ ├── escape-html@1.0.1 
  │ ├── fresh@0.2.2 
  │ ├── merge-descriptors@0.0.2 
  │ ├── methods@0.1.0 
  │ ├── parseurl@1.0.1 
  │ ├── path-to-regexp@0.1.2 
  │ ├── range-parser@1.0.0 
  │ ├── send@0.2.0 
  │ ├─┬ serve-static@1.0.1 
  │ │ └─┬ send@0.1.4 
  │ │   ├── fresh@0.2.0 
  │ │   └── range-parser@0.0.4 
  │ ├── type-is@1.0.0 
  │ └── utils-merge@1.0.0 
  ├─┬ fs-extra@0.8.1 
  │ ├── jsonfile@1.1.1 
  │ ├── ncp@0.4.2 
  │ └── rimraf@2.2.8 
  ├─┬ gig.fs@0.2.5 
  │ ├── async@0.2.10 
  │ ├─┬ express@3.4.8 
  │ │ ├─┬ commander@1.3.2 
  │ │ │ └── keypress@0.1.0 
  │ │ ├─┬ connect@2.12.0 
  │ │ │ ├── batch@0.5.0 
  │ │ │ ├── bytes@0.2.1 
  │ │ │ ├── cookie-signature@1.0.1 
  │ │ │ ├── fresh@0.2.0 
  │ │ │ ├─┬ multiparty@2.2.0 
  │ │ │ │ ├── readable-stream@1.1.14 
  │ │ │ │ └── stream-counter@0.2.0 
  │ │ │ ├── pause@0.0.1 
  │ │ │ ├── raw-body@1.1.2 
  │ │ │ ├─┬ send@0.1.4 
  │ │ │ │ └── range-parser@0.0.4 
  │ │ │ └── uid2@0.0.3 
  │ │ ├── cookie-signature@1.0.1 
  │ │ ├── fresh@0.2.0 
  │ │ ├── merge-descriptors@0.0.1 
  │ │ ├── range-parser@0.0.4 
  │ │ └── send@0.1.4 
  │ └─┬ request@2.34.0 
  │   └── tunnel-agent@0.3.0 
  ├─┬ method-override@1.0.2 
  │ └── methods@1.0.0 
  ├── mkdirp@0.3.5 
  ├─┬ npm@1.4.29 
  │ ├── abbrev@1.0.5 
  │ ├── ansi@0.3.0 
  │ ├── ansicolors@0.3.2 
  │ ├── ansistyles@0.1.3 
  │ ├── archy@0.0.2 
  │ ├── block-stream@0.0.7 
  │ ├── char-spinner@1.0.1 
  │ ├── child-process-close@0.1.1 
  │ ├── chmodr@0.1.0 
  │ ├── chownr@0.0.1 
  │ ├── cmd-shim@2.0.0  (git://github.com/othiym23/cmd-shim#12de64ca97f45ac600910092f19afacc3d5376dd)
  │ ├─┬ columnify@1.2.1 
  │ │ ├─┬ strip-ansi@1.0.0 
  │ │ │ └── ansi-regex@0.2.1 
  │ │ └─┬ wcwidth@1.0.0 
  │ │   └─┬ defaults@1.0.0 
  │ │     └── clone@0.1.18 
  │ ├── editor@0.1.0 
  │ ├── fstream@1.0.2 
  │ ├─┬ fstream-npm@1.0.0 
  │ │ └── fstream-ignore@1.0.1 
  │ ├── github-url-from-git@1.4.0 
  │ ├── github-url-from-username-repo@1.0.0 
  │ ├── glob@4.0.5 
  │ ├── graceful-fs@3.0.2 
  │ ├── inflight@1.0.1 
  │ ├── inherits@2.0.1 
  │ ├── ini@1.2.1 
  │ ├─┬ init-package-json@1.0.0 
  │ │ └── promzard@0.2.2 
  │ ├── lockfile@1.0.0 
  │ ├── lru-cache@2.5.0 
  │ ├─┬ minimatch@1.0.0 
  │ │ └── sigmund@1.0.0 
  │ ├─┬ mkdirp@0.5.0 
  │ │ └── minimist@0.0.8 
  │ ├── node-gyp@1.0.1 
  │ ├── nopt@3.0.1 
  │ ├── npm-cache-filename@1.0.1 
  │ ├── npm-install-checks@1.0.2 
  │ ├── npm-registry-client@2.0.7 
  │ ├── npm-user-validate@0.1.0 
  │ ├─┬ npmconf@1.1.8 
  │ │ └─┬ config-chain@1.1.8 
  │ │   └── proto-list@1.2.3 
  │ ├── npmlog@0.1.1 
  │ ├── once@1.3.0 
  │ ├── opener@1.3.0 
  │ ├── osenv@0.1.0 
  │ ├── path-is-inside@1.0.1 
  │ ├─┬ read@1.0.5 
  │ │ └── mute-stream@0.0.4 
  │ ├─┬ read-installed@2.0.5 
  │ │ └── util-extend@1.0.1 
  │ ├─┬ read-package-json@1.2.7 
  │ │ └── normalize-package-data@1.0.1 
  │ ├─┬ request@2.42.0 
  │ │ ├── aws-sign2@0.5.0 
  │ │ ├─┬ bl@0.9.1 
  │ │ │ └─┬ readable-stream@1.0.31 
  │ │ │   ├── core-util-is@1.0.1 
  │ │ │   ├── isarray@0.0.1 
  │ │ │   └── string_decoder@0.10.31 
  │ │ ├── caseless@0.6.0 
  │ │ ├── forever-agent@0.5.2 
  │ │ ├─┬ form-data@0.1.4 
  │ │ │ ├── async@0.9.0 
  │ │ │ ├─┬ combined-stream@0.0.5 
  │ │ │ │ └── delayed-stream@0.0.5 
  │ │ │ └── mime@1.2.11 
  │ │ ├─┬ hawk@1.1.1 
  │ │ │ ├── boom@0.4.2 
  │ │ │ ├── cryptiles@0.2.2 
  │ │ │ ├── hoek@0.9.1 
  │ │ │ └── sntp@0.2.4 
  │ │ ├─┬ http-signature@0.10.0 
  │ │ │ ├── asn1@0.1.11 
  │ │ │ ├── assert-plus@0.1.2 
  │ │ │ └── ctype@0.5.2 
  │ │ ├── json-stringify-safe@5.0.0 
  │ │ ├── mime-types@1.0.2 
  │ │ ├── node-uuid@1.4.1 
  │ │ ├── oauth-sign@0.4.0 
  │ │ ├── qs@1.2.2 
  │ │ ├── stringstream@0.0.4 
  │ │ ├─┬ tough-cookie@0.12.1 
  │ │ │ └── punycode@1.3.1 
  │ │ └── tunnel-agent@0.4.0 
  │ ├── retry@0.6.0 
  │ ├── rimraf@2.2.8 
  │ ├── semver@2.3.0 
  │ ├─┬ sha@1.2.4 
  │ │ └─┬ readable-stream@1.0.34 
  │ │   └── core-util-is@1.0.2 
  │ ├── slide@1.1.6 
  │ ├── sorted-object@1.0.0 
  │ ├── tar@1.0.1 
  │ ├── text-table@0.2.0 
  │ ├── uid-number@0.0.5 
  │ └── which@1.0.5 
  ├─┬ octonode@0.6.18 
  │ ├── deep-extend@0.5.0 
  │ ├─┬ randomstring@1.1.5 
  │ │ └── array-uniq@1.0.2 
  │ └─┬ request@2.51.0 
  │   ├─┬ bl@0.9.5 
  │   │ └── readable-stream@1.0.34 
  │   ├── caseless@0.8.0 
  │   ├─┬ combined-stream@0.0.7 
  │   │ └── delayed-stream@0.0.5 
  │   ├─┬ form-data@0.2.0 
  │   │ └─┬ mime-types@2.0.14 
  │   │   └── mime-db@1.12.0 
  │   ├── hawk@1.1.1 
  │   ├── mime-types@1.0.2 
  │   ├── oauth-sign@0.5.0 
  │   ├── qs@2.3.3 
  │   ├── stringstream@0.0.5 
  │   └── tunnel-agent@0.4.3 
  ├─┬ openpgp@0.6.5 
  │ └── node-localstorage@0.3.6 
  ├─┬ request@2.36.0 
  │ ├── aws-sign2@0.5.0 
  │ ├── forever-agent@0.5.2 
  │ ├── form-data@0.1.4 
  │ ├─┬ hawk@1.0.0 
  │ │ ├── boom@0.4.2 
  │ │ ├── cryptiles@0.2.2 
  │ │ ├── hoek@0.9.1 
  │ │ └── sntp@0.2.4 
  │ ├─┬ http-signature@0.10.1 
  │ │ ├── asn1@0.1.11 
  │ │ ├── assert-plus@0.1.5 
  │ │ └── ctype@0.5.3 
  │ ├── json-stringify-safe@5.0.1 
  │ ├── mime@1.2.11 
  │ ├── node-uuid@1.4.8 
  │ ├── oauth-sign@0.3.0 
  │ ├─┬ tough-cookie@2.3.3 
  │ │ └── punycode@1.4.1 
  │ └── tunnel-agent@0.4.3 
  ├── semver@2.2.1 
  ├─┬ socket.io@1.0.6 
  │ ├── debug@0.7.4 
  │ ├─┬ engine.io@1.3.1 
  │ │ ├── base64id@0.1.0 
  │ │ ├── debug@0.6.0 
  │ │ ├─┬ engine.io-parser@1.0.6 
  │ │ │ ├── after@0.8.1 
  │ │ │ ├── arraybuffer.slice@0.0.6 
  │ │ │ ├── base64-arraybuffer@0.1.2 
  │ │ │ ├── blob@0.0.2 
  │ │ │ └── utf8@2.0.0 
  │ │ └─┬ ws@0.4.31 
  │ │   ├── commander@0.6.1 
  │ │   ├── nan@0.3.2 
  │ │   ├── options@0.0.6 
  │ │   └── tinycolor@0.0.1 
  │ ├─┬ has-binary-data@0.1.1 
  │ │ └── isarray@0.0.1 
  │ ├─┬ socket.io-adapter@0.2.0 
  │ │ ├── debug@0.7.4 
  │ │ └── socket.io-parser@2.1.2 
  │ ├─┬ socket.io-client@1.0.6 
  │ │ ├── component-bind@1.0.0 
  │ │ ├── component-emitter@1.1.2 
  │ │ ├── debug@0.7.4 
  │ │ ├─┬ engine.io-client@1.3.1 
  │ │ │ ├── component-inherit@0.0.3 
  │ │ │ ├── debug@0.7.4 
  │ │ │ ├─┬ has-cors@1.0.3 
  │ │ │ │ └── global@2.0.1 
  │ │ │ ├── parsejson@0.0.1 
  │ │ │ ├── parseqs@0.0.2 
  │ │ │ └── xmlhttprequest@1.5.0 
  │ │ ├── indexof@0.0.1 
  │ │ ├── object-component@0.0.3 
  │ │ ├─┬ parseuri@0.0.2 
  │ │ │ └─┬ better-assert@1.0.2 
  │ │ │   └── callsite@1.0.0 
  │ │ └── to-array@0.1.3 
  │ └─┬ socket.io-parser@2.2.0 
  │   ├── debug@0.7.4 
  │   ├── emitter@1.0.1 
  │   └── json3@3.2.6 
  ├── tail@0.3.9 
  └─┬ tar@0.1.20 
    ├── block-stream@0.0.9 
    ├─┬ fstream@0.1.31 
    │ ├─┬ graceful-fs@3.0.11 
    │ │ └── natives@1.1.0 
    │ └─┬ mkdirp@0.5.1 
    │   └── minimist@0.0.8 
    └── inherits@2.0.3 

Setup Done exists, not setting up
:../FeatureTester/libs/:/root/Targets/breach_core/node_modules
Set Default Z3_PATH to ./node_modules/z3javascript/bin/libz3.so
ExpoSE Master: /root/ExpoSE/lib/Harness/src/harness.js max concurrent: 16 max paths: 1000000
Setting timeout to 900000
*** [0 done /0 queued / 1 running / 0 errors / 0% coverage ] ****** [0 done /0 queued / 1 running / 0 errors / 0% coverage ] ****** [1 done /0 queued / 0 running / 1 errors / 21% coverage ] ***
*-- Stat Module Output --*
*-- concretizations: ["defineProperty","bound log","Date","toISOString","toString"]
*-- Stat Module Done --*
*-- Test Case {"_bound":0} start 0.1393 took 17.6995s
*-- Errors occured in test {"_bound":0}
* Error: Tropigate failed because SyntaxError: Invalid number (110:70) on program /*
 * Breach: auto_updater.js
 *
 * Copyright (c) 2014, Stanislas Polu. All rights reserved.
 *
 * @author: spolu
 *
 * @log:
 * - 2014-06-02 spolu   Fix keyring location (OSX)
 * - 2014-05-27 deian   Use signature for update verification [fix #32]
 * - 2014-05-19 spolu   TMPDIR & https: check (thanks deian)
 * - 2014-05-14 spolu   Creation
 */

var events = require('events');
var async = require('async');
var api = require('exo_browser');
var request = require('request');
var zlib = require('zlib');
var crypto = require('crypto');
var semver = require('semver');
var fs = require('fs-extra');
var path = require('path');
var mkdirp = require('mkdirp');
var pgp = require('openpgp');

var common = require('./common.js');

// ## auto_updater
//
// The auto_updater is in charge of auto-updating Breach if possible (writable)
// or notify of a new version availability otherwise.
//
// The auto_updater is executed in the background it will:
// - if BREACH_NO_AUTO_UPDATE env is not defined
//   - Download https://data.breach.cc/update (JSON)
//   - Compare it with the current version
//   - if a newer version exists
//     - if `sanity_check` pass
//       - download and extract in temporary location
//       - replace files (specificities on OSX / Linux)
//       - emit `update_ready`
//     - if `sanity_check` or anything else fails
//       - emit `update_available`
//
// The auto_updater expects Bundles on OSX and a certain directory structure 
// around the native executable on Linux. This directory structure must be
// checked an recognized for the update to happen.
//
// This is not a perfect solution on Linux as we have small control on where
// Breach is installed with which permissions. We run the update there only
// if we feel confident it will work. (see `sanity_check`)
//
// ```
// @spec { }
// @emits `update_available`, `update_ready`
// ```
var auto_updater = function(spec, my) {
  var _super = {};
  my = my || {};
  spec = spec || {};

  my.VERSION = require('./../package.json').version;
  my.UPDATE_URL = require('./../package.json').auto_update.url;
  my.UPDATE_FREQUENCY = 1000 * 60 * 60 * 2;

  my.update_ready = false;
  my.update_available = false;
  my.update = null;

  //
  // _public_
  //
  var init;                /* init(cb_); */
  var install_update;      /* install_update(cb_); */

  //
  // _private_
  //
  var check_update;        /* check_last(cb_); */
  var prepare_update;      /* prepare_update(cb_); */
  var clean_update;        /* clean_update(cb_); */

  var can_write;           /* can_write(p, cb_); */
  var sanity_check;        /* sanity_check(cb_); */
  var tmp_path;            /* tmp_path(update, cb_); */

  //
  // #### _that_
  //
  var that = new events.EventEmitter();

  /****************************************************************************/
  /* PRIVATE HELPERS */
  /****************************************************************************/
  // ### can_write
  //
  // Returns an error if the path is not found or we cannot write. This function
  // is only available on POSIX platforms.
  // ```
  // @p   {string} the path to check
  // @cb_ {function(err)}
  // ```
  can_write = function(p, cb_) {
    fs.stat(p, function(err, stat) {
      if(err) {
        return cb_(err);
      }
      else {
        var result = ((process.getuid() === stat.uid) && (stat.mode * 00200) ||
                     (process.getgid() === stat.gid) && (stat.mode * 00020) ||
                     (stat.mode & 00002));
        if(!result) {
          return cb_(common.err('Cannot write to: ' + p,
                                'auto_updater:can_write_fail'));
        }
        else {
          return cb_();
        }
      }
    });
  };

  // ### sanity_check
  // 
  // Checks for the sanity of the current deployment. For auto-update to work
  // we expect the following:
  // `linux`: - [base] = `__dirname/../../../`
  //          - [base] exists and can_write
  //          - [base]/breach [linux wrapper] exists & can_write
  //          - [base]/__AUTO_UPDATE_BUNDLE_/ exists & can_write
  // `darwin`: - [base] = `__dirname/../../../../`
  //           - [base] is an OSX bundle
  //           - [base]/../ exists and can_write
  // ```
  // @cb_ {function(err)}
  // ```
  sanity_check = function(cb_) {
    if(process.platform === 'linux') {
      var base = path.resolve(__dirname, '..', '..', '..');
      var bundle = path.join(base, '__AUTO_UPDATE_BUNDLE__');
      var wrapper = path.join(base, 'breach');

      //console.log('SANITY_CHECK: ' + base);
      async.parallel([
        function(cb_) {
          can_write(base, cb_);
        },
        function(cb_) {
          can_write(bundle, cb_);
        },
        function(cb_) {
          can_write(wrapper, cb_);
        }
      ], cb_);
    }
    else if(process.platform === 'darwin') {
      var base = path.resolve(__dirname, '..', '..', '..', '..');
      var toplevel = path.resolve(base, '..');
      var contents = path.join(base, 'Contents');

      //console.log('SANITY_CHECK: ' + base);
      async.parallel([
        function(cb_) {
          can_write(base, cb_);
        },
        function(cb_) {
          can_write(toplevel, cb_);
        },
        function(cb_) {
          can_write(contents, cb_);
        },
        function(cb_) {
          if(base.substr(-4) !== '.app') {
            return cb_(common.err('Not an OSX App Bundle path: ' + base,
                                  'auto_updater:sanity_fail'));
          }
          else {
            return cb_();
          }
        }
      ], cb_);
    }
    else {
      return cb_(common.err('Platform not supported for auto-update: ' + 
                            process.platform,
                            'auto_updater:platform_not_supported'));
    }
  };

  // ### tmp_path
  //
  // Computes the temporary path depending on the platform. If the platform is
  // not supported it returns an error
  // ```
  // @update {object} the objec update
  // @cb_    {function(err, path)}
  // ```
  tmp_path = function(update, cb_) {
    switch(process.platform) {
      case 'linux': {
        var tmp_dir = process.env['TMPDIR'] || '/tmp';
        can_write(tmp_dir, function(err) {
          if(err) {
            return cb_(err);
          }
          else {
            return cb_(null, path.join(tmp_dir, '/breach.auto_update-v' + 
                                       update.version + 
                                       '-' + process.platform + 
                                       '-' + process.arch));
          }
        });
        break;
      }
      case 'darwin': {
        var tmp_dir = '/tmp';
        can_write(tmp_dir, function(err) {
          if(err) {
            return cb_(err);
          }
          else {
            return cb_(null, path.join(tmp_dir, '/breach.auto_update-v' + 
                                       update.version + 
                                       '-' + process.platform + 
                                       '-' + process.arch));
          }
        });
        break;
      }
      default: {
        return cb_(common.err('Platform not supported for auto-update: ' + 
                              process.platform,
                              'auto_updater:platform_not_supported'));
      }
    }
  };

  // ### clean_update
  //
  // Cleans up all transient data for the update
  // ````
  // @update {object} the objec update
  // @cb_ {function(err)}
  // ```
  clean_update = function(update, cb_) {
    tmp_path(update, function(err, p) {
      if(err) {
        return cb_(err);
      }
      else {
        async.parallel([
          function(cb_) {
            fs.remove(p, cb_);
          },
          function(cb_) {
            /* Testing */ //return cb_();
            fs.remove(p + '.tar.gz', cb_);
          },
          function(cb_) {
            /* Testing */ //return cb_();
            fs.remove(p + '.tar.gz.sha1sum.asc', cb_);
          }
        ], cb_);
      }
    });
  };
  
  
  // ### check_update
  //
  // Checks the UPDATE_URL for an update. If an update is found it returns the
  // update object for the platform
  // ````
  // @cb_ {function(err, update)}
  // ```
  check_update = function(cb_) {
    var result = null;
    async.waterfall([
      function(cb_) {
        var url_p = require('url').parse(my.UPDATE_URL || '');
        if(url_p.protocol !== 'https:') {
          return cb_(common.err('Invalid `UPDATE_URL` protocol: `' + 
                                url_p.protocol + ' (not https)',
                                'auto_updater:invalid_update_url_protocol'));
        }
        var options = {
          url: my.UPDATE_URL,
          json: true
        };
        request(options, function(err, res, json) {
          if(err) {
            return cb_(err);
          }
          return cb_(null, json)
        });
      },
      function(update, cb_) {
        if(update && 
           update[process.platform] && 
           update[process.platform][process.arch]) {
          return cb_(null, update[process.platform][process.arch]);
        }
        else {
          return cb_(common.err('No update information for platform: `' + 
                                process.platform + ' ' + process.arch + '`',
                                'auto_updater:no_platform_update'));
        }
      },
      function(update, cb_) {
        if(update.version !== my.VERSION) {
          return cb_(null, update);
        }
        else {
          return cb_(null, null);
        }
      }
    ], cb_);
  };

  // ### prepare_update
  //
  // Check for sanity of the local installation and proceed with downloading
  // and extracting the udpate
  // ```
  // @update {object} the update object recevied from UPDATE_URL
  // @cb_    {function(err)}
  // ```
  prepare_update = function(update, cb_) {
    var tmp = null;
    async.series([
      function(cb_) {
        sanity_check(cb_);
      },
      function(cb_) {
        clean_update(update, cb_);
      },
      function(cb_) {
        tmp_path(update, function(err, p) {
          if(err) {
            return cb_(err);
          }
          tmp = p;
          return cb_();
        });
      },
      function(cb_) {
        /* Testing */ //return cb_();
        common.log.out('[auto_updater] Downloading: ' + tmp + '.tar.gz... [' +
                       update.url + ']');
        var out = fs.createWriteStream(tmp + '.tar.gz');
        request({
          url: update.url
        }).on('error', cb_)
          .on('end', cb_)
          .pipe(out)
          .on('error', cb_);
      },
      function(cb_) {
        /* Testing */ //return cb_();
        console.log(update);
        common.log.out('[auto_updater] Downloading: ' + tmp +
                       '.tar.gz.sha1sum.asc... [' + update.signature + ']');
        var out = fs.createWriteStream(tmp + '.tar.gz.sha1sum.asc');
        request({
          url: update.signature
        }).on('error', cb_)
          .on('end', cb_)
          .pipe(out)
          .on('error', cb_);
      },
      function(cb_) {
        mkdirp(tmp, cb_);
      },
      function(cb_) {
        common.log.out('[auto_updater] Verifying: ' + tmp + '.tar.gz...');

        try {
          /* Get keys from keyring                                          */
          /* The keyring is stored in openpgp.store/openpgp-public-keys, we */
          /* explicitely specify the path here.                             */
          pgp.config.node_store = 
            path.resolve(__dirname, '..', 'openpgp.store');
          var keyring = new pgp.Keyring(),
          keys = keyring.getAllKeys();

          if(keys.length <= 0) {
            return cb_(common.err('Unexpected keyring size',
                                  'auto_updater:invalid_keyring'));
          }
        }
        catch(err) {
          return cb_(err);
        }

        /* Make sure that all the keys in the keyring are valid. At a later */
        /* point we may want to allow invalid keys so long as the update is */
        /* not signed with these.                                           */
        keys.forEach(function(key) {
          if(key.verifyPrimaryKey() !== pgp.enums.keyStatus.valid) {
            return cb_(common.err('Failed to verify key '+
                                  key.primaryKey.fingerprint,
                                  'auto_updater:invalid_key'));
          }
          common.log.out('[auto_updater] Verified ' + 
                         key.primaryKey.fingerprint +
                         ' [' + key.users[0].userId.userid + ']');
        });

        /* Verify the SHA1 of file */
        function verify_sha1sum(filename, sha1sum, cb_) {
          var hash = crypto.createHash('sha1');
          var inp = fs.createReadStream(filename);
          hash.setEncoding('hex');

          inp.on('error', cb_)
            .on('end', function() {
              hash.end();
              if(hash.read() !== sha1sum) {
                common.log.out('[auto_updater] Verifying SHA1 of `'+
                               filename + '`: FAILED!');
                return cb_(common.err('Invalid sha1sum. Expected: '+
                                      sha1sum + ', got: ' + hash.read(),
                                      'auto_updater:invalid_sha1sum'));
              } else {
                common.log.out('[auto_updater] Verifying SHA1 of `'+
                               filename + '`: OK!');
                return cb_();
              }
            });
          inp.pipe(hash);
        };

        /* Each update tarball should have an accompaning cleartext signed   */
        /* sha1sum file. This file is created as:                            */
        /*                                                                   */
        /*   sha1sum $update > $update.sha1sum                               */
        /*   gpg --armor --clearsign $update.sha1sum                         */
        /*                                                                   */
        /* Where $update is the filename of the update tarball.              */
        /* This function first verifies the signature with the supplied keys */
        /* and then the actual sha1 of the file.                             */
        /*                                                                   */
        /* Note: this function assues that the supplied keys are valid.      */
        var sig_path = tmp + '.tar.gz' + '.sha1sum.asc';
        var tar_path = tmp + '.tar.gz';
        common.log.out('[auto_updater] Reading signature file `'+
                       sig_path + '`');
        fs.readFile(sig_path, 'utf8', function(err, data) {
          if (err) { 
            return cb_(err); 
          }
          try {
            var sig = pgp.cleartext.readArmored(data);
            var verified = sig.verify(keys);
          }
          catch(err) {
            return cb_(err);
          }
          if (!verified || verified.length <= 0 || !verified[0].valid) {
            common.log.out('[auto_updater] Verifying signature: FAILED!');
            return cb_(common.err('Invalid signature.',
                                  'auto_updater:invalid_signature'));
          }
          common.log.out('[auto_updater] Verifying signature: OK!');
          return verify_sha1sum(tar_path, sig.text.split(' ')[0], cb_);
        });
      },
      function(cb_) {
        common.log.out('[auto_updater] Extracting: ' + tmp + '.tar.gz...');
        var tar = require('child_process').spawn('tar', 
          ['xfz', tmp + '.tar.gz',
           '-C', tmp, '--strip', '1']);
        tar.stdout.on('data', function (data) {
          console.log('stdout: ' + data);
        });
        tar.stderr.on('data', function (data) {
          console.log('stderr: ' + data);
        });
        tar.on('close', function (code) {
          if(code !== 0) {
            return cb_(common.err('Extraction failed with code: ' + code,
                                  'auto_updater:failed_extraction'));

          }
          return cb_();
        });
      }
    ], cb_);
  };

  /****************************************************************************/
  /* PUBLIC METHODS */
  /****************************************************************************/
  // ### install_update
  //
  // Installs update if `update_ready` is true (which means we have extracted
  // the update and we are ready to replace the current bundle)
  //
  // If everything goes acccording to plan, this function causes the process
  // to exit after spawning the new version
  // ```
  // @cb_ {function(err)} asynchronous callback
  // ```
  install_update = function(cb_) {
    if(!my.update || !my.update_ready) {
      return cb_(common.err('No update to install',
                            'auto_updater:no_update'));
    }
    if(process.platform === 'linux') {
      var dst = path.resolve(__dirname, '..', '..', '..');
      var dst_bundle = path.join(dst, '__AUTO_UPDATE_BUNDLE__');
      var dst_wrapper = path.join(dst, 'breach');
      var src = null;
      var src_bundle = null;
      var src_wrapper = null;
      async.series([
        function(cb_) {
          sanity_check(cb_);
        },
        function(cb_) {
          tmp_path(my.update, function(err, p) {
            if(err) {
              return cb_(err);
            }
            src = p;
            src_bundle = path.join(src, '__AUTO_UPDATE_BUNDLE__');
            src_wrapper = path.join(src, 'breach');
            return cb_();
          });
        },
        function(cb_) {
          fs.rename(dst_bundle, dst_bundle + '.old', cb_);
        },
        function(cb_) {
          fs.rename(dst_wrapper, dst_wrapper + '.old', cb_);
        },
        function(cb_) {
          fs.rename(src_bundle, dst_bundle, cb_);
        },
        function(cb_) {
          fs.rename(src_wrapper, dst_wrapper, cb_);
        },
        function(cb_) {
          clean_update(my.update, cb_);
        },
        function(cb_) {
          fs.remove(dst_bundle + '.old', cb_);
        },
        function(cb_) {
          fs.remove(dst_wrapper + '.old', cb_);
        },
        function(cb_) {
          common.log.out('[auto_updater] Bundle replaced. Restarting!');
          var breach = require('child_process').spawn(dst_wrapper, [], {
            detached: true,
            stdio: 'ignore'
          });
          setTimeout(function() {
            /* TODO(spolu): Smoother exit. */
            common.exit(0);
          });
        }
      ], cb_);
    }
    else if(process.platform === 'darwin') {
      var dst = path.resolve(__dirname, '..', '..', '..', '..');
      var darwin_restart = path.join(dst, 'Contents', 'Resources', 
                                     'shell', 'dist', 'darwin_restart.sh');
      var src = null;
      async.series([
        function(cb_) {
          sanity_check(cb_);
        },
        function(cb_) {
          tmp_path(my.update, function(err, p) {
            if(err) {
              return cb_(err);
            }
            src = path.join(p, 'Breach.app');
            return cb_();
          });
        },
        function(cb_) {
          fs.rename(dst, dst + '.old', cb_);
        },
        function(cb_) {
          fs.rename(src, dst, cb_);
        },
        function(cb_) {
          fs.remove(dst + '.old', cb_);
        },
        function(cb_) {
          fs.chmod(darwin_restart, '755', cb_);
        },
        function(cb_) {
          console.log(darwin_restart);
          console.log(dst);
          common.log.out('[auto_updater] Bundle replaced. Restarting!');
          var breach = require('child_process').spawn(darwin_restart, [dst], {
            detached: true,
            stdio: 'ignore'
          });
          setTimeout(function() {
            /* TODO(spolu): Smoother exit. Make sure helpers are killed. */
            common.exit(0);
          });
          return cb_();
        }
      ], cb_);
    }
    else {
      return cb_(common.err('Platform not supported for auto-update: ' + 
                            process.platform,
                            'auto_updater:platform_not_supported'));
    }
  };

  // ### init
  // 
  // Initialializes the auto_updater and starts checking for updates 
  // periodically
  // ```
  // @cb_ {function(err)} asynchronous callback
  // ```
  init = function(cb_) {
    var check = function() {
      if(my.update) return;
      check_update(function(err, update) {
        if(err) {
          common.log.error(err);
        }
        else if(update) {
          async.series([
            function(cb_) {
              prepare_update(update, cb_);
            }
          ], function(err) {
            if(err) {
              common.log.error(err);
              clean_update(update, function(err) {
                if(err) {
                  common.log.error(err);
                }
              });
              my.update = update;
              common.log.out('[auto_updater] Update available: v' + 
                             update.version)
              my.update_available = true;
              that.emit('update_available', update);
            }
            else {
              my.update = update;
              common.log.out('[auto_updater] Update ready: v' + update.version)
              my.update_ready = true;
              that.emit('update_ready', update);
            }
          });
        }
        else {
          common.log.out('[auto_updater] ' + 
                         'Breach v' + my.VERSION + ' is up to date!');
        }
      });
    };

    if(!process.env['BREACH_NO_AUTO_UPDATE']) {
      setInterval(check, my.UPDATE_FREQUENCY); check();
    }
    else {
      common.log.out('[auto_updater] Auto-update not activated');
    }
    if(cb_) return cb_();
  };

  common.method(that, 'init', init, _super);
  common.method(that, 'install_update', install_update, _super);

  common.getter(that, 'update', my, 'update');
  common.getter(that, 'update_ready', my, 'update_ready');
  common.getter(that, 'update_available', my, 'update_available');

  return that;
};

exports.auto_updater = auto_updater;
 at SyntaxError: Invalid number (110:70)
    at Parser.pp$4.raise (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2221:15)
    at Parser.pp$7.readNumber (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2896:52)
    at Parser.pp$7.getTokenFromCode (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2720:19)
    at Parser.pp$7.readToken (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2477:17)
    at Parser.readToken (/root/ExpoSE/lib/Tropigate/bin/Tokens.js:124:26)
    at Parser.pp$7.nextToken (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2468:15)
    at Parser.pp$7.next (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:2413:10)
    at Parser.pp$3.parseExprOp (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1654:14)
    at Parser.pp$3.parseExprOps (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1639:17)
    at Parser.pp$3.parseMaybeConditional (/root/ExpoSE/lib/Tropigate/node_modules/acorn/dist/acorn.js:1620:21)
* Error: TypeError: Cannot create property 'pendingcb' on boolean 'false'
*-- Replay with NO_COMPILE=1 expoSE replay '/root/ExpoSE/lib/Harness/src/harness.js' '{"_bound":0}'
*-- Coverage Data
*- File /root/ExpoSE/lib/Harness/src/harness.js. Coverage (Term): 18% Coverage (LOC): 24%
*- File /root/ExpoSE/lib/S$/bin/symbols.js. Coverage (Term): 16% Coverage (LOC): 34%
*- File /root/Targets/breach_core/node_modules/breach_core/index.js. Coverage (Term): 34% Coverage (LOC): 41%
*- File /root/Targets/breach_core/node_modules/breach_core/lib/common.js. Coverage (Term): 23% Coverage (LOC): 39%
*- File /root/Targets/breach_core/node_modules/async/lib/async.js. Coverage (Term): 10% Coverage (LOC): 14%
*- Re-run with EXPOSE_PRINT_COVERAGE=1 to print line by line coverage information
** ExpoSE Finished. 1 paths with 1 errors **
